---
title: "CDB_cycles_AnalysisOfParameters"
editor: visual
format: gfm
always_allow_html: true
---

In this notebook, we are studying the different parameters of our method Complexity Driven Bagging so as to offer a range of selection to the final user. In particular, we have three parameters:

-   Split: the number of splits in which we cut the complexity spectrum. s=1 implies we are training with one easy sample, one uniform sample and one hard sample. That is, the cycle length is 3. s=2 implies 6 samples of different complexity (cycle length is 6).

-   Alpha: to give more weight to the easiest and the hardest instances in the bootstrap sampling procedure with the aim of training the classifier with samples of higher or lower complexity (thus, enlarging the original range of complexity).

-   Number of cycles. How many times the procedure is repeated. This is totally related with the final number of ensembles.

Besides these 3 parameters, we have obtained results for different complexity measures. For the analysis of the parameters, we have aggregated results over the different complexity measures.

First, we are studying, for each one of the parameters (alpha, split, number of cycles) independently, for which values there are no significant differences and, thus, can be eliminated from the range of recommended values.

In particular:

-   For alpha and split, we aggregate over the rest of parameters since the number of tested models depends on the value of split. Therefore, for low split values, there are a lot of results but for high split values there are just a few (1000 vs 50). This requires special statistical test because the design is imbalanced. Furthermore, the comparison will not be fair since the number of models is indeed the same (we have used around 300 models in all cases) but when split is low, the number of cycles is higher and more results are saved (for example 1000) and when split is high there are only a few cycles (for example 50) but representing the same amount of models. Thus, to make the comparison fair (and not play with different samples sizes and variances), we aggregate over the rest of the results.

-   For the number of cycles, we compared the number of cycles for every combination of split and alpha. The idea is that, given a value of split and a value of alpha, we want to know when the best accuracy is obtained, when there are significant differences, etc. so as to recommend the lower number of cycles (lower number of ensembles) with the best performance. We start by identifying, for each combination of split and alpha, from what number of cycles onwards there is no significant difference in the accuracy obtained.

After this analysis, we will have a first range recommendation for every parameter. Notice that, in all cases, we take into account the mean, median and standard deviation of the accuracy.

# Parameter analysis

```{r warning=FALSE, include=FALSE}
library(tidyverse)
library(ggpubr)
library(rstatix)
library(datarium)
library(DT)
library(ggplot2)
library(patchwork)

getwd()
setwd("/home/carmen/PycharmProjects/EnsemblesComplexity/Results_general_algorithm_cycles")
#datos <- read.csv('TotalAggregatedResults_ParameterConfiguration_CDB.csv') 
# Data aggregated over complexity measures
datos <- read.csv('df_summary_data.csv') 
str(datos)
# Convert id and time into factor variables
datos <- datos %>%
  convert_as_factor(Dataset, combo_alpha_split, n_cycle,n_ensemble)
```

### Mean, median and standard deviation of accuracy for all levels of split

```{r warning=FALSE}
table_split <- datos %>%
  group_by(split) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_split)
```

```{r echo=FALSE, warning=FALSE}

# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_split, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$split <- as.numeric(df_long$split)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = split, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "split", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = split, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "split", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)

```

The higher the value of split, the higher the mean (with some exceptions) of accuracy, the lower the median and the lower the standard deviation. ¿Medium-low split values?

If we compare if there are significant differences among the different split values (once aggregated per n_cycle). We obtain that:

For the **mean of the accuracy**, there are no significant differences among:

-   4 with 6, 6 with 8 and 12

-   8 with 12,14,16

-   10 with 12, 14, 18, 22

-   12 with 14, 16, 18, 20, 22

-   14 with 16, 18, 20, 22, 26

-   From 16 to 30, almost all comparisons are not significantly different --\> maximum value of split should be 16

For the **median of the accuracy**, there are no significant differences among:

-   4 with 6 and 10

-   6 with 8, 10, 12

-   8 with 10, 12, 14, 16, 18, 20, 22

-   10 with 12, 14, 16, 18, 20, 22

-   12 with 14, 16, 18, 20, 22

-   14 with 16, 18, 20, 22, 26

-   From 16 to 30, almost all comparisons are not significantly different --\> maximum value of split should be 16

For the **std of the accuracy**, there are no significant differences among:

-   4 with 6 and 8

-   6 with 8, 10, 12

-   8 with 10, 12, 14, 16, 20

-   10 with 12, 14, 16, 20, 22, 30

-   12 with 14, 16, 20, 22, 26, 30

-   From 14 to 30, almost all comparisons are not significantly different --\> maximum value of split should be 14

### Mean, median and standard deviation of accuracy for all levels of alpha

```{r warning=FALSE}
table_alpha <- datos %>%
  group_by(alpha) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_alpha)
```

```{r echo=FALSE, warning=FALSE}

# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_alpha, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$alpha <- as.numeric(df_long$alpha)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = alpha, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "alpha", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = alpha, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "alpha", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)
```

The higher the value of alpha, the lower the mean and the median of accuracy. The standard deviation keeps lower for low-medium values. --\> Low-medium values of alpha. Lower than 12.

If we compare if there are significant differences among the different alpha values (once aggregated per n_cycle). We obtain that:

For the **mean of the accuracy**, there are ONLY significant differences among:

-   2 with 10

-   10 with 12, 14, 16, 18, 20

For the **median of the accuracy**, there are ONLY significant differences among:

-   2 with 4, 6, 8, 10, 14

-   10 with 12, 16, 20

For the **std of the accuracy**, there are NO significant differences among:

-   4 with 6 and 8

-   6 with 8, 10, 12

-   8 with 10, 12

-   From 10 to 20, almost all comparisons are not significantly different --\> maximum value of alpha should be 10

### Mean, median and standard deviation of accuracy for all levels of n_cycles (for some split values)

We cannot perform a summary of 'n_cycle' in general because the number of cycles depends on the value of split. Thus, we show some cases.

**split = 1**

```{r warning=FALSE}
table_split1 <- datos %>% filter(split == 1) %>%
  group_by(n_cycle) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_split1)

#datatable(table_split1)
```

```{r echo=FALSE, warning=FALSE}

# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_split1, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$n_cycle <- as.numeric(df_long$n_cycle)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)

```

The higher the number of cycles, the higher the mean, median of accuracy and the lower the standard deviation. For high values of cycles, the accuracy clearly stabilizes and there is no always a clear increase over time. For example, results with 89 cycles are better than with 100.

**split = 2**

```{r warning=FALSE}
table_split2 <- datos %>% filter(split == 2) %>%
  group_by(n_cycle) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_split2)
```

```{r echo=FALSE, warning=FALSE}
# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_split2, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$n_cycle <- as.numeric(df_long$n_cycle)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)

```

The higher the number of cycles, the higher the mean, median of accuracy and the lower the standard deviation. For high values of cycles, the accuracy clearly stabilizes and there is no always a clear increase over time.

**split = 4**

```{r warning=FALSE}
table_split4 <- datos %>% filter(split == 4) %>%
  group_by(n_cycle) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_split4)
```

```{r echo=FALSE, warning=FALSE}
# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_split4, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$n_cycle <- as.numeric(df_long$n_cycle)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)

```

The higher the number of cycles, the higher the mean, median of accuracy and the lower the standard deviation. For high values of cycles, the accuracy stabilizes but keeps showing an increasing trend. The longest the cycle, the less stable the trend (still increasing).

**split = 10**

```{r warning=FALSE}
table_split10 <- datos %>% filter(split == 10) %>%
  group_by(n_cycle) %>%
  summarise_at(vars(accuracy_mean_mean),  list(mean = mean, median = median, std = sd))
knitr::kable(table_split10)
```

```{r echo=FALSE, warning=FALSE}
# Convertir el dataframe al formato largo para ggplot
df_long <- tidyr::pivot_longer(table_split10, cols = c("mean", "median", "std"), 
                               names_to = "variable", values_to = "value")

df_long$n_cycle <- as.numeric(df_long$n_cycle)

# Crear el primer gráfico (mean y median) con ajuste en los breaks del eje x
g1 <- ggplot(df_long[df_long$variable %in% c("mean", "median"),], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution mean median",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("mean" = "purple", "median" = "orange"))

# Crear el segundo gráfico (std) con ajuste en los breaks del eje x
g2 <- ggplot(df_long[df_long$variable == "std",], 
             aes(x = n_cycle, y = value, color = variable)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  labs(title = "Evolution std",
       x = "n_cycle", y = "Value", color = " ") +
  theme_minimal() +
  scale_color_manual(values = c("std" = "blue"))

# Colocar los dos gráficos juntos con patchwork
g1 + g2 + plot_layout(nrow = 2)

```

The higher the number of cycles, the higher the mean, median of accuracy and the lower the standard deviation. For high values of cycles, the accuracy stabilizes but keeps showing an increasing trend. The longest the cycle, the less stable the trend (still increasing).

# Number of cycles

```{r warning=FALSE}
# Tenemos que hacer el análisis para cada combo_alpha_split
valores_combo = levels(datos$combo_alpha_split)
n_combo = length(valores_combo)
combo_friedman = data.frame(valores_combo)
combo_friedman$p_value = rep(NA,n_combo)

for (i in valores_combo){
  #print(i)
  datos_i = datos[datos$combo_alpha_split==i,]
  fri = friedman.test(accuracy_mean_mean ~ n_cycle |Dataset, data=as.matrix(datos_i))
  combo_friedman[combo_friedman$valores_combo==i,2] = fri$p.value
}
combo_friedman[combo_friedman$p_value> 0.05]
# es decir, en todos los casos hay diferencias significativas
```

Once we have checked that there are significant differences between at least one value in the combo, we make multiple comparisons to analyze when adding another cycle is not worthy since the increase is not significant.

```{r warning=FALSE}

dif_no_sig <- data.frame(valores_combo)
dif_no_sig$niveles = rep(NA,n_combo)

# Lo dejamos en comentarios porque tarda mucho

# for (i in valores_combo){
#   print(i)
#   datos_i = datos[datos$combo_alpha_split==i,]
#   datos_i$n_cycle <- factor(datos_i$n_cycle) # los niveles del factor cambian en cada subset
#   pwc2 <- datos_i %>% 
#     wilcox_test(accuracy_mean_mean ~ n_cycle, paired = TRUE, p.adjust.method = "bonferroni")
#   # Filtrar comparaciones con diferencias no significativas (suponiendo un umbral de p > 0.05)
#   no_significativas <- pwc2[pwc2$p.adj>0.1,]
# 
#   
#   # si no todas las comparaciones con ese nivel son no significativas, lo quitamos 
#   # es decir, no nos vale que solo no haya diferencia entre 3 y 5 y con el resto (3-6,3-7,etc) sí
#   max_cycles = max(as.numeric(pwc2$group2))
#   valores_check <- unique(as.numeric(no_significativas$group1))
#   for (v in valores_check){
#     if (sum(no_significativas$group1 == v) <(max_cycles - v) ){
#       no_significativas = no_significativas[no_significativas$group1!=v,]
#     }
#   }
#   
#   # Extraer los niveles de los pares con diferencias no significativas
#   niveles_no_significativos <- unique(c(no_significativas$group1, no_significativas$group2))
# 
#   dif_no_sig[dif_no_sig$valores_combo==i,2] = paste(niveles_no_significativos, collapse = ", ")
# }

#write.csv(dif_no_sig, "CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean.csv")
```

In this dataframe we have, for every combination of alpha and split, the number of cycles with no significant difference between all of them.

```{r warning=FALSE}
dif_no_sig_mean <- read.csv('CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean.csv') 
head(dif_no_sig_mean)
```

Let's relate that with the number of models to have a first view of where to stop adding models. We create two different columns:

-   num_models: it relates the first (minimum) number of cycles that presents no significant differences with all its consecutive number of cycles with the number of models it implies.

-   num_models2: it is exactly the same concept as num_models but with the second value of number of cycles in case we want to be more conservative

```{r}
# Variables to character
dif_no_sig_mean$niveles <- as.character(dif_no_sig_mean$niveles)
dif_no_sig_mean$valores_combo <- as.character(dif_no_sig_mean$valores_combo)

# Order the values 
dif_no_sig_mean$niveles <- sapply(strsplit(dif_no_sig_mean$niveles, ", "), function(x) {
  paste(sort(as.numeric(x)), collapse = ", ")
})

# Extraer el valor numérico después de "split" en la columna B
dif_no_sig_mean$valor_split <- as.numeric(gsub(".*split", "", dif_no_sig_mean$valores_combo))

# New columns with number of models
dif_no_sig_mean$num_models <- mapply(function(a, b) {
  min(as.numeric(strsplit(a, ", ")[[1]])) * (2*b +1)
}, dif_no_sig_mean$niveles, dif_no_sig_mean$valor_split)

# New columns with number of models (for the second value)
dif_no_sig_mean$num_models2 <- mapply(function(a, b) {
  valores <- sort(as.numeric(strsplit(a, ", ")[[1]])) 
  segundo_min <- ifelse(length(valores) > 1, valores[2], valores[1])  # Obtener el segundo mínimo o el primero si hay solo uno
  segundo_min * (2*b +1)
}, dif_no_sig_mean$niveles, dif_no_sig_mean$valor_split)

head(dif_no_sig_mean)
```

We perform the same analysis for the median and the standard deviation.

For the **median**:

```{r}
# dif_no_sig_mean$niveles_mediana = rep(NA,n_combo)
# 
# # Lo dejamos en comentarios porque tarda mucho
# 
# for (i in valores_combo){
#   print(i)
#   datos_i = datos[datos$combo_alpha_split==i,]
#   datos_i$n_cycle <- factor(datos_i$n_cycle) # los niveles del factor cambian en cada subset
#   pwc2 <- datos_i %>%
#     wilcox_test(accuracy_mean_median ~ n_cycle, paired = TRUE, p.adjust.method = "bonferroni")
#   # Filtrar comparaciones con diferencias no significativas (suponiendo un umbral de p > 0.05)
#   no_significativas <- pwc2[pwc2$p.adj>0.1,]
# 
# 
#   # si no todas las comparaciones con ese nivel son no significativas, lo quitamos
#   # es decir, no nos vale que solo no haya diferencia entre 3 y 5 y con el resto (3-6,3-7,etc) sí
#   max_cycles = max(as.numeric(pwc2$group2))
#   valores_check <- unique(as.numeric(no_significativas$group1))
#   for (v in valores_check){
#     if (sum(no_significativas$group1 == v) <(max_cycles - v) ){
#       no_significativas = no_significativas[no_significativas$group1!=v,]
#     }
#   }
# 
#   # Extraer los niveles de los pares con diferencias no significativas
#   niveles_no_significativos <- unique(c(no_significativas$group1, no_significativas$group2))
# 
#   dif_no_sig_mean[dif_no_sig_mean$valores_combo==i,'niveles_mediana'] = paste(niveles_no_significativos, collapse = ", ")
# }

#write.csv(dif_no_sig_mean, "CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean_median.csv")
```

For the **standard deviation**:

```{r}
# dif_no_sig_mean$niveles_std = rep(NA,n_combo)
# 
# # Lo dejamos en comentarios porque tarda mucho
# 
# for (i in valores_combo){
#   print(i)
#   datos_i = datos[datos$combo_alpha_split==i,]
#   datos_i$n_cycle <- factor(datos_i$n_cycle) # los niveles del factor cambian en cada subset
#   pwc2 <- datos_i %>%
#     wilcox_test(accuracy_mean_std ~ n_cycle, paired = TRUE, p.adjust.method = "bonferroni")
#   # Filtrar comparaciones con diferencias no significativas (suponiendo un umbral de p > 0.05)
#   no_significativas <- pwc2[pwc2$p.adj>0.1,]
# 
# 
#   # si no todas las comparaciones con ese nivel son no significativas, lo quitamos
#   # es decir, no nos vale que solo no haya diferencia entre 3 y 5 y con el resto (3-6,3-7,etc) sí
#   max_cycles = max(as.numeric(pwc2$group2))
#   valores_check <- unique(as.numeric(no_significativas$group1))
#   for (v in valores_check){
#     if (sum(no_significativas$group1 == v) <(max_cycles - v) ){
#       no_significativas = no_significativas[no_significativas$group1!=v,]
#     }
#   }
# 
#   # Extraer los niveles de los pares con diferencias no significativas
#   niveles_no_significativos <- unique(c(no_significativas$group1, no_significativas$group2))
# 
#   dif_no_sig_mean[dif_no_sig_mean$valores_combo==i,'niveles_std'] = paste(niveles_no_significativos, collapse = ", ")
# }

#write.csv(dif_no_sig_mean, "CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean_median_std.csv")
```

Now we relate the number of cycles with the number of ensembles for all statistical measures (mean, median, std):

```{r warning=FALSE}
dif_no_sig_all <- read.csv('CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean_median_std.csv') 
head(dif_no_sig_all)
```

```{r warning=FALSE}
# Variables to character
dif_no_sig_all$niveles_mediana <- as.character(dif_no_sig_all$niveles_mediana)
dif_no_sig_all$niveles_std <- as.character(dif_no_sig_all$niveles_std)
dif_no_sig_all$valores_combo <- as.character(dif_no_sig_all$valores_combo)

# Order the values 
dif_no_sig_all$niveles_mediana <- sapply(strsplit(dif_no_sig_all$niveles_mediana, ", "), function(x) {
  paste(sort(as.numeric(x)), collapse = ", ")
})

dif_no_sig_all$niveles_std <- sapply(strsplit(dif_no_sig_all$niveles_std, ", "), function(x) {
  paste(sort(as.numeric(x)), collapse = ", ")
})


# New columns with number of models
dif_no_sig_all$num_models_mediana <- mapply(function(a, b) {
  min(as.numeric(strsplit(a, ", ")[[1]])) * (2*b +1)
}, dif_no_sig_all$niveles_mediana, dif_no_sig_all$valor_split)

dif_no_sig_all$num_models_std <- mapply(function(a, b) {
  min(as.numeric(strsplit(a, ", ")[[1]])) * (2*b +1)
}, dif_no_sig_all$niveles_std, dif_no_sig_all$valor_split)

# New columns with number of models (for the second value)
dif_no_sig_all$num_models2_mediana <- mapply(function(a, b) {
  valores <- sort(as.numeric(strsplit(a, ", ")[[1]])) 
  segundo_min <- ifelse(length(valores) > 1, valores[2], valores[1])  # Obtener el segundo mínimo o el primero si hay solo uno
  segundo_min * (2*b +1)
}, dif_no_sig_all$niveles_mediana, dif_no_sig_all$valor_split)

dif_no_sig_all$num_models2_std <- mapply(function(a, b) {
  valores <- sort(as.numeric(strsplit(a, ", ")[[1]])) 
  segundo_min <- ifelse(length(valores) > 1, valores[2], valores[1])  # Obtener el segundo mínimo o el primero si hay solo uno
  segundo_min * (2*b +1)
}, dif_no_sig_all$niveles_std, dif_no_sig_all$valor_split)

# Sacamos tb el valor en ciclos
dif_no_sig_all$cycles_mean <- sapply(strsplit(dif_no_sig_all$niveles, ", "), function(x) {
  min(as.numeric(x))})

dif_no_sig_all$cycles_median <- sapply(strsplit(dif_no_sig_all$niveles_mediana, ", "), function(x) {
  min(as.numeric(x))})

dif_no_sig_all$cycles_std <- sapply(strsplit(dif_no_sig_all$niveles_std, ", "), function(x) {
  min(as.numeric(x))})


head(dif_no_sig_all)

#write.csv(dif_no_sig_all, "CDB_cycles_ParametersComboAlphaSplit_dif_no_signif_cycles_mean_median_std_num_models.csv")
```

We have performed multiple comparisons analysis for the number of cycles with respect to the mean, median and std of the accuracy and found the number of cycles above which there is no significant difference for each statistical measure. Now we have to take the maximum number of cycles over the three statistical measure to select a range of cycles. After that we can analyze which is the best cycle structure (for example, a high number of short cycles or a short number of long cycles).

```{r}
dif_no_sig_all$max_num_cycles <- apply(X=dif_no_sig_all[,c('cycles_mean','cycles_median','cycles_std')], MARGIN=1, FUN=max)
dif_no_sig_all$max_num_models <- apply(X=dif_no_sig_all[,c('num_models','num_models_mediana','num_models_std')], MARGIN=1, FUN=max)

```

If we analyze the number of models above which there are no significant different, we can see that the maximum value is 294 and quartile 75% is 175, implying that our maximum tested number of models (300) is ok and that lower number of models in an ensemble can obtain competitive accuracy results.

```{r}
p<-ggplot(dif_no_sig_all, aes(x=max_num_models)) + 
  geom_histogram(color="black", fill="white")
p
```

```{r}
summary(dif_no_sig_all$max_num_models)
```

From the study of alpha and split we know that:

-   From 16 to 30, almost all comparisons are not significantly different --\> **maximum value of split should be 16. Domain: \[1, 2, 4, 6, 8, 10, 12, 14\]**

-   Maximum alpha value should be 10-12: **Domain: \[2, 4, 6, 8, 10\]**

Note that these ranges go inline with the previous study where we make no distinction about cycles.

Let's filter now the previous information according to these ranges:

```{r}
dif_no_sig_all$valor_alpha <- as.numeric(gsub("alpha([0-9]+)-split[0-9]+", "\\1", dif_no_sig_all$valores_combo))
# Filtrar el dataset para eliminar las filas donde alpha > 12 y split > 16
df_filtered <- dif_no_sig_all[(dif_no_sig_all$valor_alpha < 12 & dif_no_sig_all$valor_split < 16), ]
```

```{r}
summary(df_filtered$max_num_models)
```

After filtering the not desired values for alpha and split, the maximum number of models where the significant differences stops is 200.

Este df_filtered son 40 filas, es decir, 40 combinaciones de alpha y split. Entonces vamos a estudiarlos 1 a 1. Hago un gráfico de la evolución del accuracy en cada caso y señalo cuando se supone que no hay diferencias significativas. Esto lo hacemos de nuevo agregado por medidas de complejidad y luego elijo un par y lo visualizo para ellas. Aquí estoy un poco perdida porque en general se ve que según aumenta el número de modelos, aumenta el accuracy pero supuestamente ya no de forma significativa y deberíamos guiarnos por eso. Yo creo que el orden es:

1.  Hacer estos gráficos de evoluación del accuracy para los 40 casos y mirarlo para alguna medida de complejidad

2.  Seleccionar el mejor valor de accuracy para estos 40 casos

3.  Sacar conclusiones de la comparación de 1 y 2

4.  Para nuestro método, escoger el mejor valor de parámetros en 2 casos:

    1.  alpha, split y n_cycles reducido en función de las comparaciones múltiples

    2.  alpha y split reducido en función de las comparaciones múltiples y n_cycles sin reducir

    Comparar estas 2 versiones nuestras standard bagging y mixed bagging con el mismo número de parámetros

AHORA AQUÍ TENGO QUE RESUMIR A PARTIR DE CUANDO NO HAY DIFERENCIAS SIGNIFICATIVAS PARA CADA CASO Y RELACIONARLO CON EL NÚMERO DE ENSEMBLES

LUEGO HACER LO MISMO PARA STD Y CON ELLO FILTRAR N_CYCLES

¿Qué es mejor: ciclos cortos o largos?
