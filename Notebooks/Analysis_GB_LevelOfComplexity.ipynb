{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analysis of Gradient Boosting Results + Complexity Measures per Level of complexity",
   "id": "1d18d25ec7e34500"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we have a total of 112 datasets. We want to split them according to their level of complexity and study the results in the different categories. The objective is to investigate if we obtain better results than classic boosting for some levels of complexity (for example, for the hardest datasets).",
   "id": "8ccfe7a14161ca94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:04:58.999775Z",
     "start_time": "2025-01-15T19:04:58.996302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "\n",
    "os.chdir(\"..\")\n",
    "root_path = os.getcwd()"
   ],
   "id": "29b202f7e1faa2e1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:05:03.446265Z",
     "start_time": "2025-01-15T19:05:03.443277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_csv = os.path.join(root_path, 'Results_GB')\n",
    "os.chdir(path_csv)"
   ],
   "id": "80b28640b4a60dd9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:05:05.411997Z",
     "start_time": "2025-01-15T19:05:05.409627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#colour_palette_personalized = [\"#FFD700\", \"#00CED1\", \"#FF1493\",\"#F1F1F1\"]\n",
    "colour_palette_personalized = {\n",
    "    \"classic\": \"#FFD700\",   # yellow\n",
    "    \"sample_weight_easy\": \"#C7F7FF\", # blue\n",
    "    \"sample_weight_easy_x2\": \"#00CED1\", # blue\n",
    "    \"sample_weight_hard\": \"#FFB3DA\",    # magenta\n",
    "    \"sample_weight_hard_x2\": \"#FF1493\",    # magenta\n",
    "    \"Classic\": \"#FFD700\",   # yellow\n",
    "    \"Easy\": \"#00CED1\", # blue\n",
    "    \"Hard\": \"#FF1493\",    # magenta\n",
    "}\n",
    "\n"
   ],
   "id": "3cc4bd32322bdb48",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:05:18.474804Z",
     "start_time": "2025-01-15T19:05:14.222358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "specific_path = os.path.join(path_csv, '*Aggregated*.csv')\n",
    "selected_files = glob.glob(specific_path)\n",
    "all_datasets = pd.concat([pd.read_csv(f) for f in selected_files], ignore_index=True)"
   ],
   "id": "4ecddc0d0c311197",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We already have the complexity characteristics of each dataset in the csv complex_info_dataset_20250115.csv. We read it and split the datasets according to the complexity values of each complexity measure.",
   "id": "c8f116903a2e9ea0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:06:40.249741Z",
     "start_time": "2025-01-15T19:06:40.232405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_complex = os.path.join(root_path, 'datasets/complexity_info')\n",
    "os.chdir(path_complex)\n",
    "df_complex = pd.read_csv('complex_info_dataset_20250115.csv')\n",
    "df_complex.head()"
   ],
   "id": "33b0820ffe25abe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    dataset  Hostility       kDN        DS       DCP  \\\n",
       "0     analcatdata_gviolence   0.229730  0.083784  0.219595  0.050778   \n",
       "1  analcatdata_japansolvent   0.250000  0.265385  0.384615  0.000000   \n",
       "2      analcatdata_vineyard   0.158120  0.188462  0.605078  0.493827   \n",
       "3            arrhythmia_cfs   0.205752  0.316372  0.573684  0.177085   \n",
       "4                Australian   0.175362  0.185507  0.615459  0.211243   \n",
       "\n",
       "       TD_U      TD_P        MV        CB       CLD  ...        N2       LSC  \\\n",
       "0  0.489865  1.000000  0.116908  0.657901  0.187850  ...  0.249374  0.589575   \n",
       "1  0.461538  0.461538  0.035613  0.666174  0.336514  ...  0.400943  0.768121   \n",
       "2  0.500986       NaN  0.088889  0.662551  0.418386  ...  0.245928  0.975808   \n",
       "3  0.572607  0.692232  0.071031  0.664311  0.331718  ...  0.471772  0.981821   \n",
       "4  0.568237  0.761594  0.088288  0.662623  0.220640  ...  0.398111  0.969318   \n",
       "\n",
       "   LSradius         H         U        F1        F2        F3        F4  \\\n",
       "0  0.608601  0.027027  0.600292  0.405405  0.000000  0.612981  0.911090   \n",
       "1  0.791536  0.038462  0.776809  0.766827  0.538542  0.757220  0.916458   \n",
       "2  0.948771  0.004274  0.975912  0.849003  0.736191  0.799548  0.862728   \n",
       "3  0.715307  0.004425  0.981899  0.745515  0.603953  0.801924  0.989752   \n",
       "4  0.799725  0.002899  0.969406  0.519876  0.664697  0.757345  0.995492   \n",
       "\n",
       "                  dataset.1  \n",
       "0     analcatdata_gviolence  \n",
       "1  analcatdata_japansolvent  \n",
       "2      analcatdata_vineyard  \n",
       "3            arrhythmia_cfs  \n",
       "4                Australian  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Hostility</th>\n",
       "      <th>kDN</th>\n",
       "      <th>DS</th>\n",
       "      <th>DCP</th>\n",
       "      <th>TD_U</th>\n",
       "      <th>TD_P</th>\n",
       "      <th>MV</th>\n",
       "      <th>CB</th>\n",
       "      <th>CLD</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>LSC</th>\n",
       "      <th>LSradius</th>\n",
       "      <th>H</th>\n",
       "      <th>U</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>dataset.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analcatdata_gviolence</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0.219595</td>\n",
       "      <td>0.050778</td>\n",
       "      <td>0.489865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116908</td>\n",
       "      <td>0.657901</td>\n",
       "      <td>0.187850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249374</td>\n",
       "      <td>0.589575</td>\n",
       "      <td>0.608601</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.600292</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612981</td>\n",
       "      <td>0.911090</td>\n",
       "      <td>analcatdata_gviolence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analcatdata_japansolvent</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>0.666174</td>\n",
       "      <td>0.336514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400943</td>\n",
       "      <td>0.768121</td>\n",
       "      <td>0.791536</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.776809</td>\n",
       "      <td>0.766827</td>\n",
       "      <td>0.538542</td>\n",
       "      <td>0.757220</td>\n",
       "      <td>0.916458</td>\n",
       "      <td>analcatdata_japansolvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analcatdata_vineyard</td>\n",
       "      <td>0.158120</td>\n",
       "      <td>0.188462</td>\n",
       "      <td>0.605078</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.500986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.662551</td>\n",
       "      <td>0.418386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245928</td>\n",
       "      <td>0.975808</td>\n",
       "      <td>0.948771</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.975912</td>\n",
       "      <td>0.849003</td>\n",
       "      <td>0.736191</td>\n",
       "      <td>0.799548</td>\n",
       "      <td>0.862728</td>\n",
       "      <td>analcatdata_vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arrhythmia_cfs</td>\n",
       "      <td>0.205752</td>\n",
       "      <td>0.316372</td>\n",
       "      <td>0.573684</td>\n",
       "      <td>0.177085</td>\n",
       "      <td>0.572607</td>\n",
       "      <td>0.692232</td>\n",
       "      <td>0.071031</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.331718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471772</td>\n",
       "      <td>0.981821</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.981899</td>\n",
       "      <td>0.745515</td>\n",
       "      <td>0.603953</td>\n",
       "      <td>0.801924</td>\n",
       "      <td>0.989752</td>\n",
       "      <td>arrhythmia_cfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australian</td>\n",
       "      <td>0.175362</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.615459</td>\n",
       "      <td>0.211243</td>\n",
       "      <td>0.568237</td>\n",
       "      <td>0.761594</td>\n",
       "      <td>0.088288</td>\n",
       "      <td>0.662623</td>\n",
       "      <td>0.220640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398111</td>\n",
       "      <td>0.969318</td>\n",
       "      <td>0.799725</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.969406</td>\n",
       "      <td>0.519876</td>\n",
       "      <td>0.664697</td>\n",
       "      <td>0.757345</td>\n",
       "      <td>0.995492</td>\n",
       "      <td>Australian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T19:07:12.185690Z",
     "start_time": "2025-01-15T19:07:12.183572Z"
    }
   },
   "cell_type": "code",
   "source": "list_CM = ['Hostility','kDN','DCP','TD_U','CLD','N1','N2','LSC','F1']",
   "id": "8bd4ec94d18c5d65",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para este análisis lo que voy a hacer es:\n",
    " * Dividir el rango de cada medida de complejidad en 3: fácil, medio, difícil. Esto lo haré automáticamente con alguna función de python puesto que para algunas medidas (por ejemplo, F1 cuyo rango es [0,1] pero con valores muy concentrados en torno al 0.9, no sé interpretar los valores).\n",
    "  * Para cada medida de complejidad, estudiar los resultados en estos cortes. Miraré media, mediana y std de accuracy y el WTL.\n",
    "  * Luego hago el estudio desde la otra perspectiva. Divido los datasets en función de si, con esa medida de complejidad, gano, empato o pierdo. Creo esas categorías y hago una análisis exploratorio de las mismas. Por ejemplo, grafico la complejidad de dichas categorías mediante boxplots."
   ],
   "id": "8c49728bc25ca47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9ac67d0eb2a0f96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b220ec6003b002e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e6824597b571db5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
