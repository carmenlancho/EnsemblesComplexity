ci_lower = ci_lower[!is.na(ci_lower)][-11]
ci_upper = ci_upper[!is.na(ci_upper)][-11]
plotCI(x=rr,ui=ci_upper,li =ci_lower)
plotCI(x=rr,ui=ci_upper,li =ci_lower,col=4,type="b",pch=19)
plotCI(x=rr,ui=ci_upper,li =ci_lower,col=4,type="b",pch=19,xlab="",xaxt="n")
axis(side=1,at = 1:length(EstudiosSeleccionados$author),
labels=EstudiosSeleccionados$author, cex=0.1, las = 2)
plotCI(x=rr,ui=ci_upper,li =ci_lower,col=4,type="b",pch=19,xlab="",xaxt="n")
axis(side=1,at = 1:length(EstudiosSeleccionados$author),
labels=EstudiosSeleccionados$author, cex=0.1, las = 2)
40+12+24
40+4+6
16+4+6
26*4
library(palmerpenguins)
data(penguins)
penguins
colSums(is.na(penguins))
colSums(is.na(penguins))[colSums(is.na(penguins))>0]
1000000/5
36*4
144/2
135/3
mean(c(0.4, 0.5, 0.4, 0.6, 0.4, 0.4, 0.6, 0.5, 0.5, 0.7))
0.4, 0.5, 0.4, 0.6, 0.4, 0.4, 0.6, 0.5, 0.5, 0.7
c(0.4, 0.5, 0.4, 0.6, 0.4, 0.4, 0.6, 0.5, 0.5, 0.7)
(0.4 +0.5 +0.4+ 0.6+ 0.4+ 0.4+ 0.6+ 0.5+ 0.5+ 0.7)/10
mean(c(0.2, 0.2, 0.1, 0.3, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2))
mean(c(0.2, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2, 0.2))
mean(c(0.1, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2))
mean(c(0.6, 0.6, 0.7, 0.7, 0.4, 0.6, 0.5, 0.7, 0.4, 0.6))
mean(c(0.4, 0.5, 0.4, 0.6, 0.4, 0.4, 0.6, 0.5, 0.5, 0.7))
mean(c(0.6332945285215367, 0.5890570430733411, 0.6239813736903376, 0.6286379511059371, 0.6263096623981373, 0.6228172293364377, 0.6239813736903376, 0.6181606519208381, 0.6321303841676368, 0.5972060535506403))
6.83*2
16+14+14+12+3
1/0.32
1/0.6
1/0.5
data <- airquality
data[4:10,3] <- rep(NA,7)
data[1:5,4] <- NA
data
data <- data[-c(5,6)]
summary(data)
library(mice)
install.packages("mice")
library(mice)
md.pattern(data)
# imputing the missing data
tempData <- mice(data,m=5,maxit=50,meth='pmm',seed=500)
summary(tempData)
completedData <- complete(tempData,1)
completedData
42800*0.07
62060*0.07
84530*0.07
(42800-2800)*0.07
40000*0.07
(62060-4060)*0.07
(45000+7000+6000)*0.07
(84530-5530)*0.07
(60000+10000+9000)*0.07
33/4
7*8
0.653036137846854
-0.576155470808413
0.653036137846854 - 0.576155470808413
0.652455738196208 - 0.581624848894848
0.671386959723571-0.594041999326626
0.67*1.25
mean(c(0.5122222222222222, 0.5094444444444445, 0.5516666666666666, 0.5433333333333333, 0.5138888888888888, 0.5372222222222223, 0.5277777777777778, 0.5222222222222223, 0.5288888888888889, 0.5438888888888889))
mean(c(0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4))
mean(c(0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.3, 0.4))
mean(c(0.5, 0.5, 0.5, 0.4, 0.5, 0.6, 0.5, 0.7, 0.4, 0.5))
mean(c(0.4, 0.5, 0.4, 0.5, 0.4, 0.5, 0.6, 0.6, 0.6, 0.6
))
mean(c(0.2, 0.3, 0.3, 0.2, 0.3, 0.3, 0.3, 0.3, 0.2, 0.3))
207/3000
150/3000
mean(c(0.59, 0.5522222222222222, 0.5627777777777778, 0.6005555555555555, 0.5616666666666666, 0.5761111111111111, 0.5772222222222222, 0.5394444444444444, 0.5738888888888889, 0.5627777777777778))
mean(c(0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2))
mean(c(0.2, 0.3, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3))
mean(c())
mean(c(0.3, 0.3, 0.3, 0.3, 0.2, 0.3, 0.3, 0.2, 0.3, 0.3))
mean(c(0.6, 0.3, 0.4, 0.4, 0.4, 0.5, 0.5, 0.4, 0.5, 0.5))
mean(c(0.4, 0.5, 0.6, 0.5, 0.5, 0.5, 0.5, 0.6, 0.4, 0.6))
mean(c(0.2, 0.3, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2))
150/3000
14/9
275/650
375/900
575/1190
6000/6
1000/6
166/6
27/6
100/(100+890)
7+5+14+3+6+3+9+7+3+15+6+6+4
10+5+13+12+7+16+12
44*7
22*7
22*8
176-88
10+5+13+13+12+7+16+12
10+12+3+8+2+13+5+3+15+7+2+7+4
12+7+12+9+14+7+13+11
91+85
88+88
10+15+6+3+10+4+3+15+4+3+4+9
12+7+13+12+15+7+15+9
8*3*3
8*2*4
72+64
6+3+7+3+2+7+4+2+8+5+8+5+4+1+7+5
136/2
77/136
8*2*3
8*4
48+32
4+4+6+8+8+
pp
4+4+4+2+8+8+7+3
0.390
(0.145+0.634)/2
0.049*53*2.2
0.049*53*2.2*60
0.049*53*2.2*65
200*5
50/3
312/6
312/7
mean(c(0.3, 0.2, 0.3, 0.3, 0.3, 0.2, 0.3, 0.2, 0.3, 0.2))
300*5*9
200*5*9
36+44+38+33+29
263+275+267+266+250
1251+249+261+1239
1258+242+251+1249
log(0)
log2(0)
-log2(0.1)
-log2(0.9)
-log2(c(0.5,0.6,0.7,0.8,0.9,1))
ĺog2(0.3)
-log2(0.3)
-0.33*log2(0.33)-0.33*log2(0.33)-0.33*log2(0.33)
-0.25*log2(0.25)-0.25*log2(0.25)-0.25*log2(0.25)-0.25*log2(0.25)
-0.25*log(0.25)-0.25*log(0.25)-0.25*log(0.25)-0.25*log(0.25)
-log2(0.25)
-log2(0.33)
-0.5*log2(0.5)-0.25*log2(0.25)-0.1*log2(0.1)-0.15*log2(0.15)
-log2(1)
library(MASS)
library(mnormt)
library(mvtnorm)
library(pracma) # to integrate
# Function to calculate overlapping between two bivariate normal distributions
normal_overlap_2D <- function(mu11,mu12,mu21,mu22,sd11,sd12,sd21,sd22){
# Minimum of both distributions
min.f1f2_2D <- function(x,y) {
mu11 = 0
mu12 = 0
mu21 = 8
mu22 = 0
Sigma1 <- matrix(c(80,0,0,5),2,2)
Sigma2 <- matrix(c(8,0,0,8),2,2)
xs = matrix(cbind(c(x,y)),ncol=2)
f1 = dmvnorm(xs, mean=c(mu11,mu12),Sigma1)
f2 = dmvnorm(xs, mean=c(mu21,mu22),Sigma2)
pmin(f1, f2)
}
# we obtain the integral approximation with two different functions to double check
ovl1 = dblquad(Vectorize(min.f1f2_2D), -200, 200, -200, 200)
ovl2 = integral2(min.f1f2_2D,  -200, 200, -200, 200)
# danger: outside some limits the integrate approximations fail
return(list(ovl1,ovl2))
}
normal_overlap_2D()
# Function to calculate overlapping between two bivariate normal distributions
normal_overlap_2D <- function(mu11,mu12,mu21,mu22,sd11,sd12,sd21,sd22){
# Minimum of both distributions
min.f1f2_2D <- function(x,y) {
# normal parameters are changed here
mu11 = 0
mu12 = 0
mu21 = 8
mu22 = 0
Sigma1 <- matrix(c(80,0,0,5),2,2)
Sigma2 <- matrix(c(8,0,0,8),2,2)
xs = matrix(cbind(c(x,y)),ncol=2)
f1 = dmvnorm(xs, mean=c(mu11,mu12),Sigma1)
f2 = dmvnorm(xs, mean=c(mu21,mu22),Sigma2)
pmin(f1, f2)
}
# we obtain the integral approximation with two different functions to double check
ovl1 = dblquad(Vectorize(min.f1f2_2D), -200, 200, -200, 200)
ovl2 = integral2(min.f1f2_2D,  -200, 200, -200, 200)
# danger: outside some limits the integrate approximations fail
return(list(ovl1,ovl2))
}
normal_overlap_2D()
5*13
5*12
5*10
550*4
40*16
40*16*13
8320/60
139/24
640/60
5*28
9*5
12*5
7*5
9*5
12*5
7*5
306/4
9*20
12*20
7*20
13*20
mean(c(26, 27.5, 31, 28 ,25.5 ,30.5 ,32 ,31.5))
sum(c(26, 27.5, 31, 28 ,25.5 ,30.5 ,32 ,31.5))/8
((2.17*0.8)/0.9)²
((2.17*0.8)/0.9)^2
((2.17*0.8)/0.9)**2
((2.17*0.8)/0.9)
((2.17*2.8)/0.9)**2
4*(6/7)-1
16/7
17/7
3*6-14
3*(6/7)-2
18/7
18-14
4/7
(1/6)*(1/6)*((5/6)**4)
56/3
0.24*4
48*9*200
64*9*200
179-36
mean(c(0.87681159, 0.87681159, 0.87681159, 0.87681159, 0.87681159,
0.87681159, 0.87681159, 0.87681159, 0.87681159, 0.87681159,
0.87681159, 0.87681159, 0.87681159, 0.87681159, 0.87681159,
0.87681159, 0.87681159, 0.87681159, 0.55797101, 0.55797101,
0.55797101, 0.55797101, 0.55797101, 0.55797101, 0.55797101,
0.55797101, 0.55797101, 0.55797101, 0.55797101, 0.55797101,
0.55797101, 0.55797101, 0.55797101, 0.55797101, 0.55797101,
0.55797101, 0.55797101, 0.55797101, 0.55797101, 0.55797101,
0.55797101, 0.55797101, 0.55797101, 0.55797101, 0.55797101))
mean(c(0.82608696, 0.87681159, 0.77372263, 0.84671533, 0.79562044,
0.86131387, 0.8540146 , 0.86861314, 0.91240876, 0.91240876))
describe(iris)
library(Hmisc)
describe(iris)
describe(iris)
exp(2.373)/(1+exp(2.373))
exp(2.373)/(1+exp(2.373))
a = 1.846
exp(a)/(1+exp(a))
a = -0.791
exp(a)/(1+exp(a))
a = 3.4
exp(a)/(1+exp(a))
## Libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyverse)
library(emmeans)
library(optimx)
56+35
USArrests
prcomp(USArrests)
prcomp(USArrests, scale = TRUE)
prcomp(USArrests, scale = TRUE)$s
prcomp(USArrests, scale = TRUE)$x
pnorm(0.975)
qnorm(0.975)
0.317 + qnorm(0.975)*0.01695
library(dplyr)
library(MASS)
# Muestreo
# TRAIN TEST VALIDATION
numero_total = nrow(Boston)
set.seed(123456) # reproductivilidad
# 50% para TRAIN
indices_train = sample(1:numero_total, .5*numero_total)
Boston_train = Boston[indices_train,]
# 25% para TEST
indices = seq(1:numero_total)
indices_test = sample(indices[-indices_train], .25*numero_total)
Boston_test = Boston[indices_test,]
# 25% para VALIDATION
indices_validation = indices[-c(indices_train,indices_test)]
# OJO... Estos datos sólo los usaremos el último día de clase
# en el último minuto... y responderá a la pregunta siguiente:
# ¿Cómo va a funcionar nuestro modelo cuando lleguen nuevos datos
# al sistema?
Boston_validation = Boston[indices_validation,]
# Respuesta
Boston_train =
Boston_train %>%
mutate(precio = as.factor(medv>=30), log_crim=log(crim),sq_lstat = sqrt(lstat) )
Boston_train2 =
Boston_train %>%
mutate(s_crim=scale(log_crim),
s_lstat = scale(sq_lstat),
s_tax = scale(tax),
s_rad = scale(rad),
s_indus = scale(indus)
)
pca1 = princomp(Boston_train2[,c("s_crim",
"s_lstat",
"s_tax",
"s_rad",
"s_indus")])
summary(pca1)
# peso de cada variable en cada componente
pca1$loadings
# ahora vamos a pintar los puntos
plot(pca1$scores, col=as.numeric(Boston_train2$precio)+1,pch=19)
cmds1= cmdscale(dist(Boston_train2[,c("s_crim",
"s_lstat",
"s_tax",
"s_rad",
"s_indus")]),eig=TRUE)
cmds1
# plot solution
x <- cmds1$points[,1]
y <- cmds1$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
main="Metric MDS", type="n")
text(x, y, labels = row.names(Boston_train2), cex=.7)
Boston_train2
USArrests
prcomp(USArrests)
plot(prcomp(USArrests))
summary(prcomp(USArrests))
prcomp(USArrests, scale = TRUE)
plot(prcomp(USArrests,scale=T))
summary(prcomp(USArrests,scale=T))
plot(prcomp(USArrests,scale=T)$x[,1:2])
plot(prcomp(USArrests,scale=T)$x[,1:2],type="n")
text(prcomp(USArrests,scale=T)$x[,1:2],rownames(USArrests))
biplot(prcomp(USArrests,scale=T))
sqrt((-0.5358995)**2 +(-0.5831836)**2 + (-0.2781909)**2 + (-0.5434321)**2)
corr(USArrests)
cor(USArrests)
USArrests
View(USArrests)
USArrests
prcomp(USArrests)
prcomp(USArrests, scale = TRUE)
plot(prcomp(USArrests,scale=T))
summary(prcomp(USArrests,scale=T))
plot(prcomp(USArrests,scale=T)$x[,1:2],type="n")
text(prcomp(USArrests,scale=T)$x[,1:2],rownames(USArrests))
biplot(prcomp(USArrests,scale=T))
mean(c(0.3,0.4,0.6))
mean(c(0.5,0.2,0.2))
mean(c(0,0.2,0.2))
1-0.43333
mean(c(0.4,0.2,0.2))
0.018+0.122
18/146
122/146
qnormal(0.975)
qnorm(0.975)
qnorm(0.9725)
1-0.025
qnorm(0.975)
0.5*0.5
z = qnorm(0.975)
std = 0.25 # var 0.5
e = 0.1
n = (z*std/e)²
n = (z*std/e)**2
n
e = 0.05
n = (z*std/e)**2
n
(1.96*1.5/0.05)**2
(1.64*0.25/0.05)**2
sqrt(0.5)
0.25*0.25
0.7071068*0.7071068
n = (z*sqrt(std)/e)**2
n
(1.64*sqrt(0.5)/0.05)**2
z
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.9,N=Inf)
library(samplingbook)
install.packages("samplingbook")
library(samplingbook)
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.9,N=Inf)
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.95,N=Inf)
n = (z*sqrt(std)/e)**2
n
z = qnorm(0.95)
n = (z*sqrt(std)/e)**2
n
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.95,N=Inf)
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.972,N=Inf)
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.90,N=Inf)
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.90,N=Inf)
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.85,N=Inf)
z = qnorm(0.95)
z
1-0.05/2
z = qnorm(0.975)
var = 0.5 # var 0.5
e = 0.05
n = (z*sqrt(std)/e)**2
n
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.95,N=Inf)
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.95,N=Inf)
alpha = 0.05
z = qnorm(1-alpha/2)
var = 0.5 # var 0.5
e = 0.05
n = (z*sqrt(std)/e)**2
n
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.95,N=Inf)
n = ((z*sqrt(std))/e)^2
n
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.90,N=Inf)
alpha = 0.1
z = qnorm(1-alpha/2)
var = 0.5 # var 0.5
e = 0.05
n= ((z*sqrt(std))/e)^2
n
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.90,N=Inf)
alpha = 0.1
z = qnorm(1-alpha/2)
var = 0.5 # var 0.5
e = 0.05
n= ((z*sqrt(std))/e)^2
n
alpha = 0.1
var = 0.5 # var 0.5
e = 0.05
n = ((qnorm(1-alpha/2)*sqrt(std))/e)^2
n
sample.size.mean(e=0.05,S=sqrt(0.5),level=0.90,N=Inf)
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.90,N=Inf)
e = 0.1
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
alpha = 0.2
e = 0.1
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.80,N=Inf)
alpha = 0.2
e = 0.15
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
alpha = 0.2
e = 0.11
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.85,N=Inf)
sample.size.mean(e=0.11,S=sqrt(0.5),level=0.85,N=Inf)
sample.size.mean(e=0.12,S=sqrt(0.5),level=0.85,N=Inf)
sample.size.mean(e=0.13,S=sqrt(0.5),level=0.85,N=Inf)
sample.size.mean(e=0.1,S=sqrt(0.5),level=0.8,N=Inf)
sample.size.mean(e=0.11,S=sqrt(0.5),level=0.8,N=Inf)
sample.size.mean(e=0.115,S=sqrt(0.5),level=0.8,N=Inf)
alpha = 0.2
e = 0.115
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
alpha = 0.2
e = 0.11
var = 0.5 # var 0.5
n = ((qnorm(1-alpha/2)*sqrt(var))/e)^2
n
sample.size.mean(e=0.115,S=sqrt(0.5),level=0.8,N=Inf)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(datarium)
getwd()
setwd("/home/carmen/PycharmProjects/EnsemblesComplexity/Results_general_algorithm")
datos <- read.csv('SummarizeResults_ParameterConfiguration_CDB.csv')
str(datos)
# Convert id and time into factor variables
datos <- datos %>%
convert_as_factor(Dataset, alpha,split, weights)
## Libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyverse)
library(emmeans)
library(optimx)
library(ggsignif)
m1b = lmer(accuracy_mean_std ~ 1 + weights + split + alpha +
(1 + weights + split + alpha | Dataset), datos)
